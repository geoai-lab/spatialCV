{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62e827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import spacv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset for obesity prevalence prediction\n",
    "\n",
    "df_obesity = pd.read_csv(\"../Data/Obesity/Obesity.csv\")\n",
    "df_obesity[[\"GEOID\"]] = df_obesity[[\"GEOID\"]].astype(str)\n",
    "y = df_obesity['obesity_cr']\n",
    "df_obesity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_columns = ['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male',\n",
    "                 '% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool',\n",
    "                 'median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built',\n",
    "                 'median year units built','% renter-occupied housing units','population density']\n",
    "num_features = len(using_columns)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the geodataframe for the data\n",
    "\n",
    "gdf_obesity = gpd.GeoDataFrame(df_obesity, geometry=gpd.points_from_xy(df_obesity['Lonpro'], df_obesity['Latpro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ec478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization function\n",
    "\n",
    "def standarize_data(data, stats):\n",
    "    return (data - stats['mean'])/ stats['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ac993",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e2fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# random split\n",
    "\n",
    "y_dnn_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "ten_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in ten_fold.split(df_obesity):\n",
    "    print(\"fold:\", str(i))\n",
    "    X_train, X_test = df_obesity.iloc[train_index], df_obesity.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train[using_columns]\n",
    "    X_test = X_test[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    dnn_model = keras.models.Sequential([\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(256,activation=\"relu\"),\n",
    "        keras.layers.Dense(32,activation=\"relu\"),\n",
    "        keras.layers.Dense(240,activation=\"relu\"),\n",
    "        keras.layers.Dense(96,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    #early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    dnn_model.compile(optimizer=\"adam\", loss=keras.losses.mean_squared_error, metrics=[keras.metrics.mean_squared_error])\n",
    "    dnn_model.fit(x=scaled_X_train, y=y_train, epochs=50, verbose=2) #callbacks=[early_stop],\n",
    "    \n",
    "    this_y_predict = dnn_model.predict(scaled_X_test).flatten()\n",
    "    y_dnn_socio_predict = y_dnn_socio_predict + this_y_predict.tolist()\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179f5e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dnn_socio_rmse = mean_squared_error(y_true , y_dnn_socio_predict, squared=False)\n",
    "dnn_socio_r2 = r2_score(y_true, y_dnn_socio_predict)\n",
    "print(\"rmse: \" + str(round(dnn_socio_rmse,4)), \"r2: \" + str(round(dnn_socio_r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6cf93",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clustering-based spatial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076e24b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split the data based on their coordinates using k-means clustering algorithm\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42).fit(df_obesity[['Lonpro','Latpro']])\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "plt.scatter(df_obesity['Lonpro'], df_obesity['Latpro'], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd101603",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# label the cluster index of each sample. \n",
    "\n",
    "df_obesity_cluster = df_obesity.copy()\n",
    "df_obesity_cluster[\"cluster\"] = kmeans.labels_.tolist()\n",
    "df_obesity_cluster[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb6dbf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_dnn_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "group_index = df_obesity_cluster['cluster'].values\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=10)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in group_kfold.split(df_obesity_cluster, y, group_index):\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train, X_test = df_obesity.iloc[train_index], df_obesity.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train[using_columns]\n",
    "    X_test = X_test[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    dnn_model = keras.models.Sequential([\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(256,activation=\"relu\"),\n",
    "        keras.layers.Dense(32,activation=\"relu\"),\n",
    "        keras.layers.Dense(240,activation=\"relu\"),\n",
    "        keras.layers.Dense(96,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    #early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    dnn_model.compile(optimizer=\"adam\", loss=keras.losses.mean_squared_error, metrics=[keras.metrics.mean_squared_error])\n",
    "    dnn_model.fit(x=scaled_X_train, y=y_train, epochs=50,   verbose=2) #callbacks=[early_stop],\n",
    "    \n",
    "    this_y_predict = dnn_model.predict(scaled_X_test).flatten()\n",
    "    y_dnn_socio_predict = y_dnn_socio_predict + this_y_predict.tolist()\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "    i = i + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc1944",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dnn_socio_rmse = mean_squared_error(y_true , y_dnn_socio_predict, squared=False)\n",
    "dnn_socio_r2 = r2_score(y_true, y_dnn_socio_predict)\n",
    "print(\"rmse: \" + str(round(dnn_socio_rmse,4)), \"r2: \" + str(round(dnn_socio_r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93513ad5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid-based spatial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31c2bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_cv = spacv.HBLOCK(3, 3, method='unique', buffer_radius=0).split(gdf_obesity['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c9a49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_dnn_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in grid_cv:\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train, X_test = df_obesity.iloc[train_index], df_obesity.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train[using_columns]\n",
    "    X_test = X_test[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    dnn_model = keras.models.Sequential([\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(256,activation=\"relu\"),\n",
    "        keras.layers.Dense(32,activation=\"relu\"),\n",
    "        keras.layers.Dense(240,activation=\"relu\"),\n",
    "        keras.layers.Dense(96,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    #early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    dnn_model.compile(optimizer=\"adam\", loss=keras.losses.mean_squared_error, metrics=[keras.metrics.mean_squared_error])\n",
    "    dnn_model.fit(x=scaled_X_train, y=y_train, epochs=50,   verbose=2) #callbacks=[early_stop],\n",
    "    \n",
    "    this_y_predict = dnn_model.predict(scaled_X_test).flatten()\n",
    "    y_dnn_socio_predict = y_dnn_socio_predict + this_y_predict.tolist()\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd1167",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dnn_socio_rmse = mean_squared_error(y_true , y_dnn_socio_predict, squared=False)\n",
    "dnn_socio_r2 = r2_score(y_true, y_dnn_socio_predict)\n",
    "print(\"rmse: \" + str(round(dnn_socio_rmse,4)), \"r2: \" + str(round(dnn_socio_r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e947b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Geo-attribute-based spatial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3634ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load the file for showing which borough each census tract is located in.\n",
    "\n",
    "gdf_tract_borough = gpd.read_file(\"../Data/Obesity/gdf_tract_borough.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132279b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_obesity_block = df_obesity.merge(gdf_tract_borough[['GEOID','index_righ']], how='left', left_on=\"GEOID\", right_on=\"GEOID\")\n",
    "df_obesity_block.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fba357",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_obesity_block.index_righ.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc67a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_dnn_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "block = df_obesity_block['index_righ'].values\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in group_kfold.split(df_obesity, y, block):\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train, X_test = df_obesity.iloc[train_index], df_obesity.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train[using_columns]\n",
    "    X_test = X_test[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    dnn_model = keras.models.Sequential([\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(256,activation=\"relu\"),\n",
    "        keras.layers.Dense(32,activation=\"relu\"),\n",
    "        keras.layers.Dense(240,activation=\"relu\"),\n",
    "        keras.layers.Dense(96,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    #early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    dnn_model.compile(optimizer=\"adam\", loss=keras.losses.mean_squared_error, metrics=[keras.metrics.mean_squared_error])\n",
    "    dnn_model.fit(x=scaled_X_train, y=y_train, epochs=50,   verbose=2) #callbacks=[early_stop],\n",
    "    \n",
    "    this_y_predict = dnn_model.predict(scaled_X_test).flatten()\n",
    "\n",
    "    y_dnn_socio_predict = y_dnn_socio_predict + this_y_predict.tolist()\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e4762",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dnn_socio_rmse = mean_squared_error(y_true , y_dnn_socio_predict, squared=False)\n",
    "dnn_socio_r2 = r2_score(y_true, y_dnn_socio_predict)\n",
    "print(\"rmse: \" + str(round(dnn_socio_rmse,4)), \"r2: \" + str(round(dnn_socio_r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c7359",
   "metadata": {},
   "source": [
    "## Spatial leave-one-out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeaeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the radius of buffer as the 0.05 quantile of distances of data\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "lng_lat_coords = np.array(df_obesity[['Lonpro','Latpro']])\n",
    "\n",
    "distances = [distance.euclidean(p1, p2) for p1, p2 in combinations(lng_lat_coords, 2)]\n",
    "distances_array=np.array(distances)\n",
    "np.quantile(distances_array, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and test data for each fold using the buffer_radius\n",
    "\n",
    "skcv = spacv.SKCV(n_splits=1995, buffer_radius=3219, random_state=42).split(gdf_obesity['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc398aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dnn_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in skcv:\n",
    "    print(\"fold:\", str(i))\n",
    "    X_train, X_test = df_obesity.iloc[train_index], df_obesity.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train[using_columns]\n",
    "    X_test = X_test[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    dnn_model = keras.models.Sequential([\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(160,activation=\"relu\"),\n",
    "        keras.layers.Dense(256,activation=\"relu\"),\n",
    "        keras.layers.Dense(32,activation=\"relu\"),\n",
    "        keras.layers.Dense(240,activation=\"relu\"),\n",
    "        keras.layers.Dense(96,activation=\"relu\"),\n",
    "        keras.layers.Dense(208,activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    #early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    dnn_model.compile(optimizer=\"adam\", loss=keras.losses.mean_squared_error, metrics=[keras.metrics.mean_squared_error])\n",
    "    dnn_model.fit(x=scaled_X_train, y=y_train, epochs=50, verbose=2) #callbacks=[early_stop],\n",
    "    \n",
    "    this_y_predict = dnn_model.predict(scaled_X_test).flatten()\n",
    "    y_dnn_socio_predict = y_dnn_socio_predict + this_y_predict.tolist()\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8028c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_socio_rmse = mean_squared_error(y_true , y_dnn_socio_predict, squared=False)\n",
    "dnn_socio_r2 = r2_score(y_true, y_dnn_socio_predict)\n",
    "print(\"rmse: \" + str(round(dnn_socio_rmse,4)), \"r2: \" + str(round(dnn_socio_r2,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
