{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import spacv\n",
    "from spacv.grid_builder import construct_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ee995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset for domestic violence prediction\n",
    "\n",
    "df_DV = pd.read_csv(\"../Data/DV/DV.csv\")\n",
    "df_DV[[\"CensusBloc\"]] = df_DV[[\"CensusBloc\"]].astype(str)\n",
    "y = df_DV[\"DV rate\"]\n",
    "df_DV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the geodataframe for the data\n",
    "\n",
    "gdf_DV = gpd.GeoDataFrame(df_DV, geometry=gpd.points_from_xy(df_DV['Lonpro'], df_DV['Latpro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictors\n",
    "\n",
    "using_columns = ['population density', '% White', '% Ame Indi and AK Native', '% Asian', '% Nati Hawa and Paci Island', \n",
    "                 '% Hispanic', '% age 18-29', '% age 30-39', '% age 40-49', '% age 50-59', '% age >60', 'med income', \n",
    "                 '% unemployment', '% female hh', '% <highschool', '% security inc', '% assistant inc', '% renter hh', \n",
    "                 '% stay >=5yrs']\n",
    "num_features = len(using_columns)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a30b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization function\n",
    "\n",
    "def standarize_data(data, stats):\n",
    "    return (data - stats['mean'])/stats['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba09770",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4cddd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "y_true = []\n",
    "\n",
    "ten_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in ten_fold.split(df_DV):\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train_all, X_test_all = df_DV.iloc[train_index], df_DV.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train_all[using_columns]\n",
    "    X_test = X_test_all[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    X_scaled_train = standarize_data(X_train, training_stat)\n",
    "    X_scaled_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=80, max_features='sqrt', random_state=42, bootstrap=False)\n",
    "    rf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    rf_predict = rf.predict(X_scaled_test)    \n",
    "    y_predict = y_predict + list(rf_predict)\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_predict, squared=False)  # False means return RMSE value\n",
    "r2 = r2_score(y_true, y_predict)\n",
    "print(\"rmse: \" + str(round(rmse,4)), \"r2: \" + str(round(r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906e8d4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clustering-based spatial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476b053",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split the data based on their coordinates using k-means clustering algorithm\n",
    "\n",
    "coordinates = df_DV[['Lonpro','Latpro']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42).fit(coordinates)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "plt.scatter(coordinates['Lonpro'], coordinates['Latpro'], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8bc326",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# label the cluster index of each sample. \n",
    "\n",
    "df_DV_cluster = df_DV.copy()\n",
    "df_DV_cluster[\"cluster\"] = kmeans.labels_.tolist()\n",
    "df_DV_cluster[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a2e0e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "y_true = []\n",
    "\n",
    "group_index = df_DV_cluster['cluster'].values\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=10)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in group_kfold.split(df_DV_cluster, y, group_index):\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train_all, X_test_all = df_DV_cluster.iloc[train_index], df_DV_cluster.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train_all[using_columns]\n",
    "    X_test = X_test_all[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    X_scaled_train = standarize_data(X_train, training_stat)\n",
    "    X_scaled_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=200, max_features='sqrt', random_state=42, bootstrap=False)\n",
    "    rf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    rf_predict = rf.predict(X_scaled_test)    \n",
    "    y_predict = y_predict + list(rf_predict)\n",
    "    y_true = y_true + y_test.tolist()    \n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_predict, squared=False)  # False means return RMSE value\n",
    "r2 = r2_score(y_true, y_predict)\n",
    "print(\"rmse: \" + str(round(rmse,4)), \"r2: \" + str(round(r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86489bdc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid-based spatial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d5281",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split the data using grids\n",
    "\n",
    "grid_cv = spacv.HBLOCK(3, 3, method='unique', buffer_radius=0).split(gdf_DV['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850e1aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "y_true = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in grid_cv:\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train_all, X_test_all = df_DV.iloc[train_index], df_DV.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train_all[using_columns]\n",
    "    X_test = X_test_all[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    X_scaled_train = standarize_data(X_train, training_stat)\n",
    "    X_scaled_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=200, max_features='sqrt', random_state=42, bootstrap=False)\n",
    "    rf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    rf_predict = rf.predict(X_scaled_test)    \n",
    "    y_predict = y_predict + list(rf_predict)\n",
    "    y_true = y_true + y_test.tolist()\n",
    "        \n",
    "    i = i + 1\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_predict, squared=False)  # False means return RMSE value\n",
    "r2 = r2_score(y_true, y_predict)\n",
    "print(\"rmse: \" + str(round(rmse,4)), \"r2: \" + str(round(r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32660fe2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Geo-attribute-based spatial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d32f5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the CBG-level and neighborhoods-level data of Chicago \n",
    "\n",
    "gdf_cbg = gpd.read_file(\"../Data/DV/chicago_cbg.shp\")\n",
    "gdf_cbg = gdf_cbg.to_crs('epsg:26916')\n",
    "\n",
    "gdf_neigh = gpd.read_file(\"../Data/DV/chicago_neighborhoods.shp\")\n",
    "gdf_neigh = gdf_neigh.to_crs('epsg:26916')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bdf3d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Determine which neighborhood each CBG is located in based on the intersection area.\n",
    "\n",
    "fid_list = []\n",
    "\n",
    "for index1, row1 in gdf_cbg.iterrows():\n",
    "    geometry1 = row1[\"geometry\"]\n",
    "    percentage = 0\n",
    "    fid = 0\n",
    "    for index2, row2 in gdf_neigh.iterrows():\n",
    "        geometry2 = row2[\"geometry\"]\n",
    "        fid_temp = index2\n",
    "        perc_temp = (geometry1.intersection(geometry2).area/geometry1.area)*100\n",
    "        if perc_temp > percentage:\n",
    "            percentage = perc_temp\n",
    "            fid = fid_temp\n",
    "    fid_list.append(fid)\n",
    "\n",
    "gdf_cbg[\"neigh_id\"] = fid_list\n",
    "gdf_cbg.neigh_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72496ecf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_DV_block = df_DV.merge(gdf_cbg[['CensusBloc','neigh_id']], how='left', left_on=\"CensusBloc\", right_on=\"CensusBloc\")\n",
    "df_DV_block.neigh_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bccc97c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "y_true = []\n",
    "\n",
    "block = df_DV_block['neigh_id'].values\n",
    "group_kfold = GroupKFold(n_splits=96)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in group_kfold.split(df_DV, y, block):\n",
    "    print(\"fold:\", str(i))\n",
    "\n",
    "    X_train_all, X_test_all = df_DV.iloc[train_index], df_DV.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train_all[using_columns]\n",
    "    X_test = X_test_all[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    X_scaled_train = standarize_data(X_train, training_stat)\n",
    "    X_scaled_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=200, max_features='sqrt', random_state=42, bootstrap=False) \n",
    "    rf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    rf_predict = rf.predict(X_scaled_test)    \n",
    "    y_predict = y_predict + list(rf_predict)\n",
    "    y_true = y_true + y_test.tolist()    \n",
    "        \n",
    "    i = i + 1\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_predict, squared=False)  # False means return RMSE value\n",
    "r2 = r2_score(y_true, y_predict)\n",
    "print(\"rmse: \" + str(round(rmse,4)), \"r2: \" + str(round(r2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c1496e",
   "metadata": {},
   "source": [
    "## Spatial leave-one-out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef08f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the radius of buffer as the 0.05 quantile of distances of data\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "lng_lat_coords = np.array(df_DV[['Lonpro','Latpro']])\n",
    "\n",
    "distances = [distance.euclidean(p1, p2) for p1, p2 in combinations(lng_lat_coords, 2)]\n",
    "distances_array=np.array(distances)\n",
    "np.quantile(distances_array, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de776610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and test data for each fold using the buffer_radius\n",
    "\n",
    "skcv = spacv.SKCV(n_splits=2146, buffer_radius=3004, random_state=42).split(gdf_DV['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "y_true = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in skcv:\n",
    "    print(\"fold:\", str(i))\n",
    "    \n",
    "    X_train_all, X_test_all = df_DV.iloc[train_index], df_DV.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train_all[using_columns]\n",
    "    X_test = X_test_all[using_columns]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    X_scaled_train = standarize_data(X_train, training_stat)\n",
    "    X_scaled_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=80, max_features='sqrt', random_state=42, bootstrap=False) \n",
    "    rf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    rf_predict = rf.predict(X_scaled_test)    \n",
    "    y_predict = y_predict + list(rf_predict)\n",
    "    y_true = y_true + y_test.tolist()    \n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_predict, squared=False)  # False means return RMSE value\n",
    "r2 = r2_score(y_true, y_predict)\n",
    "print(\"rmse: \" + str(round(rmse,4)), \"r2: \" + str(round(r2,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
